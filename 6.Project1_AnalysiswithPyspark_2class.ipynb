{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252a7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7192e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import lit\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.sql.functions import when\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "from datetime import datetime\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6235287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:18:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/28 02:18:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Rating').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5dde6",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ace938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.csv(\"shopee_final.csv\",header=True\n",
    "                      ,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79fcaf03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- processed_text: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a712bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.withColumn('class',lit('fake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0956ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:18:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , processed_text, class\n",
      " Schema: _c0, processed_text, class\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/tony.ng/Documents/DS-ML/final_project/project1/shopee_final.csv\n",
      "+---+--------------------+--------+\n",
      "|_c0|      processed_text|   class|\n",
      "+---+--------------------+--------+\n",
      "|  0|miếng dán hơi_dầy...|negative|\n",
      "|  1|miếng dán rất_tồi...|negative|\n",
      "|  2|cường_lực trắng m...|negative|\n",
      "|  3|hàng cảm_quan đầu...|negative|\n",
      "|  4|chất_lượng cường_...|negative|\n",
      "|  5|kính chất_lượng k...|negative|\n",
      "|  6|kính cường_lực dở...|negative|\n",
      "|  7|bị_vỡ bắt_làm hoà...|negative|\n",
      "|  8|kính bụi dính kín...|negative|\n",
      "|  9|đóng hàng cường_l...|negative|\n",
      "| 10|hàng cường_lực xi...|negative|\n",
      "| 11|không_vừa gần_chấ...|negative|\n",
      "| 12|                  bé|negative|\n",
      "| 13|         đo thử chán|negative|\n",
      "| 14|   hàng miếng bảo_vệ|negative|\n",
      "| 15|sản_phẩm miết rất...|negative|\n",
      "| 16|chính_xác sản_phẩ...|negative|\n",
      "| 17|     hàng hãng lưu_ý|negative|\n",
      "| 18|chất_lượng sản_ph...|negative|\n",
      "| 19|cường_lực mô_tả b...|negative|\n",
      "+---+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.withColumn(\"class\", when(df1['class'] == \"negative\",\"negative\") \\\n",
    "      .when(df1['class'] == \"neutral\",\"negative\") \\\n",
    "      .otherwise(df1['class']))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e2623f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934543"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17376be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|   class| count|\n",
      "+--------+------+\n",
      "|positive|636052|\n",
      "|negative|298491|\n",
      "+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:=========================>                                (7 + 9) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.groupby('class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ebad0",
   "metadata": {},
   "source": [
    "### Precprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e53746f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn('length', length(df2['processed_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab983c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:18:16 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , processed_text, class\n",
      " Schema: _c0, processed_text, class\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/tony.ng/Documents/DS-ML/final_project/project1/shopee_final.csv\n",
      "+---+--------------------+--------+------+\n",
      "|_c0|      processed_text|   class|length|\n",
      "+---+--------------------+--------+------+\n",
      "|  0|miếng dán hơi_dầy...|negative|    28|\n",
      "|  1|miếng dán rất_tồi...|negative|    57|\n",
      "|  2|cường_lực trắng m...|negative|    23|\n",
      "|  3|hàng cảm_quan đầu...|negative|    63|\n",
      "|  4|chất_lượng cường_...|negative|   101|\n",
      "+---+--------------------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594b92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:18:16 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , processed_text, class\n",
      " Schema: _c0, processed_text, class\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/tony.ng/Documents/DS-ML/final_project/project1/shopee_final.csv\n",
      "+--------+-----------------+------------------+\n",
      "|   class|         avg(_c0)|       avg(length)|\n",
      "+--------+-----------------+------------------+\n",
      "|positive|477209.3752444769|44.500778346973405|\n",
      "|negative| 446093.398494427| 41.68132393148086|\n",
      "+--------+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:===>                                                    (1 + 15) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.groupBy('class').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68208f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df2.select('processed_text','class','length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7d0c9b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|      processed_text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|miếng dán hơi_dầy...|negative|    28|\n",
      "|miếng dán rất_tồi...|negative|    57|\n",
      "|cường_lực trắng m...|negative|    23|\n",
      "|hàng cảm_quan đầu...|negative|    63|\n",
      "|chất_lượng cường_...|negative|   101|\n",
      "|kính chất_lượng k...|negative|    41|\n",
      "|kính cường_lực dở...|negative|   126|\n",
      "|bị_vỡ bắt_làm hoà...|negative|    32|\n",
      "|kính bụi dính kín...|negative|    33|\n",
      "|đóng hàng cường_l...|negative|    32|\n",
      "|hàng cường_lực xi...|negative|    61|\n",
      "|không_vừa gần_chấ...|negative|    22|\n",
      "|                  bé|negative|     2|\n",
      "|         đo thử chán|negative|    11|\n",
      "|   hàng miếng bảo_vệ|negative|    17|\n",
      "|sản_phẩm miết rất...|negative|    89|\n",
      "|chính_xác sản_phẩ...|negative|   151|\n",
      "|     hàng hãng lưu_ý|negative|    15|\n",
      "|chất_lượng sản_ph...|negative|   122|\n",
      "|cường_lực mô_tả b...|negative|    82|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e317dc2",
   "metadata": {},
   "source": [
    "### Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6eefe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data = data.filter(data['processed_text'].isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c2e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33669"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9121783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(data['processed_text'].isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380b755",
   "metadata": {},
   "source": [
    "### Duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7d272ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:==============>                                         (4 + 12) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|      processed_text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|aaaaaaa giá rẻ ch...|positive|    32|\n",
      "|aaaaaaaaaaaaaaaaa...|positive|    53|\n",
      "|aaaaaaaaaaaaaaaaa...|positive|    49|\n",
      "|aaaaaaaaaaaaaaaaa...|positive|    56|\n",
      "|abajajaj djsjana ...|positive|    28|\n",
      "|acid dịch_vị giúp...|negative|    99|\n",
      "|add ground liver ...|positive|    21|\n",
      "|addjficuc êwưabja...|positive|    49|\n",
      "|     adidas gửi nhầm|negative|    15|\n",
      "|admin kích_hoạt b...|negative|    27|\n",
      "|      agcejzvebgrhdg|positive|    14|\n",
      "|agsgdhbdjs djdjsh...|positive|    58|\n",
      "|ahslffl shwodlddj...|positive|    42|\n",
      "|airpod đầu bị_lỗi...|negative|    88|\n",
      "|akfjso kakdjdnd đ...|positive|    47|\n",
      "|               akwkd|negative|     5|\n",
      "|amin đóng gói hàn...|positive|    40|\n",
      "|android không_khẳ...|negative|    41|\n",
      "|         android máy|negative|    11|\n",
      "|aoa thahsjhsbsjxa...|positive|    61|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:=================================================>      (14 + 2) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data.dropDuplicates(['processed_text']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dc32248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|      processed_text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|miếng dán hơi_dầy...|negative|    28|\n",
      "|miếng dán rất_tồi...|negative|    57|\n",
      "|cường_lực trắng m...|negative|    23|\n",
      "|hàng cảm_quan đầu...|negative|    63|\n",
      "|chất_lượng cường_...|negative|   101|\n",
      "|kính chất_lượng k...|negative|    41|\n",
      "|kính cường_lực dở...|negative|   126|\n",
      "|bị_vỡ bắt_làm hoà...|negative|    32|\n",
      "|kính bụi dính kín...|negative|    33|\n",
      "|đóng hàng cường_l...|negative|    32|\n",
      "|hàng cường_lực xi...|negative|    61|\n",
      "|không_vừa gần_chấ...|negative|    22|\n",
      "|                  bé|negative|     2|\n",
      "|         đo thử chán|negative|    11|\n",
      "|   hàng miếng bảo_vệ|negative|    17|\n",
      "|sản_phẩm miết rất...|negative|    89|\n",
      "|chính_xác sản_phẩ...|negative|   151|\n",
      "|     hàng hãng lưu_ý|negative|    15|\n",
      "|chất_lượng sản_ph...|negative|   122|\n",
      "|cường_lực mô_tả b...|negative|    82|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef64cc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900874"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62a8ca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|   class| count|\n",
      "+--------+------+\n",
      "|positive|614122|\n",
      "|negative|286752|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupby('class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9051d",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0b3c30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 2\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "major_df = data.filter(col(\"class\") == 'positive')\n",
    "minor_df = data.filter(col(\"class\") == 'negative')\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fd56152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|      processed_text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|dán hơi_lỗi ảnh t...|positive|    25|\n",
      "|            kèm giấy|positive|     8|\n",
      "|miếng kiểu thèm b...|positive|    76|\n",
      "|gói hàng rất_có t...|positive|   123|\n",
      "|dán mặt lưng xr t...|positive|   109|\n",
      "|sản_phẩm tốt khôn...|positive|    53|\n",
      "|không_đủ hàng khô...|positive|    50|\n",
      "|gãy hẳn nửa giá c...|positive|    33|\n",
      "|hàng chất_lượng s...|positive|    71|\n",
      "|ảnh thực dán vô h...|positive|    23|\n",
      "|kính sọc chống tr...|positive|    37|\n",
      "|tạm hình quảng_cá...|positive|    31|\n",
      "|dán dán màn_hình ...|positive|    35|\n",
      "|                  vỡ|positive|     2|\n",
      "|          cơ_bản giá|positive|    10|\n",
      "|hàng remax autobo...|positive|    30|\n",
      "|cường_lực dán tốt...|positive|    40|\n",
      "|đóng gói đẹp khs ...|positive|    52|\n",
      "|tạm ổn ádfghjklzm...|positive|    27|\n",
      "|hàng đóng_gói kỹ ...|positive|    30|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "combined_df_2 = sampled_majority_df.unionAll(minor_df)\n",
    "combined_df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16a4cb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|   class| count|\n",
      "+--------+------+\n",
      "|positive|307836|\n",
      "|negative|286752|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df_2.groupby('class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d85e9b",
   "metadata": {},
   "source": [
    "### Feature & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "380fb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BsTextExtractor(Transformer, HasInputCol, HasOutputCol):\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(BsTextExtractor, self).__init__() \n",
    "        kwargs = self._input_kwargs \n",
    "        self.setParams(**kwargs)\n",
    "        \n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None): \n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    def _transform(self, dataset):\n",
    "        def f(s):\n",
    "            cleaned_text = BeautifulSoup(s).text \n",
    "            return cleaned_text\n",
    "        t = StringType()\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udf(f, t)(in_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c29777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extractor = BsTextExtractor(inputCol=\"processed_text\", outputCol=\"cleaned_text\")\n",
    "tokenizer = Tokenizer(inputCol='cleaned_text', outputCol='token_text')\n",
    "stopremove= StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens', outputCol='c_vec')\n",
    "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\n",
    "ham_spam_to_num = StringIndexer(inputCol='class',outputCol='label', handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "680a2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols =['tf_idf','length'],\n",
    "                           outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c521930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages=[ham_spam_to_num,\n",
    "                                  text_extractor,\n",
    "                                  tokenizer,\n",
    "                                  stopremove,\n",
    "                                  count_vec,\n",
    "                                  idf,\n",
    "                                  clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1793128a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cleaner = data_prep_pipe.fit(combined_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eac4664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaner.transform(combined_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd0c6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.select('label','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f18affa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:25:08 WARN DAGScheduler: Broadcasting large task binary with size 1900.5 KiB\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(63765,[35,57,69,...|\n",
      "|  0.0|(63765,[142,191,6...|\n",
      "|  0.0|(63765,[53,187,65...|\n",
      "|  0.0|(63765,[1,18,21,5...|\n",
      "|  0.0|(63765,[13,69,72,...|\n",
      "|  0.0|(63765,[0,20,69,1...|\n",
      "|  0.0|(63765,[1,4,28,67...|\n",
      "|  0.0|(63765,[15,244,42...|\n",
      "|  0.0|(63765,[0,1,2,27,...|\n",
      "|  0.0|(63765,[35,69,284...|\n",
      "|  0.0|(63765,[20,214,22...|\n",
      "|  0.0|(63765,[22,25,28,...|\n",
      "|  0.0|(63765,[18,53,69,...|\n",
      "|  0.0|(63765,[309,63764...|\n",
      "|  0.0|(63765,[15,1386,6...|\n",
      "|  0.0|(63765,[1,2,5204,...|\n",
      "|  0.0|(63765,[1,20,41,6...|\n",
      "|  0.0|(63765,[1,5,21,24...|\n",
      "|  0.0|(63765,[22,27,537...|\n",
      "|  0.0|(63765,[1,7,50,14...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91be6233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|  0.0|307836|\n",
      "|  1.0|286752|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "232c8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = clean_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d6c877",
   "metadata": {},
   "source": [
    "## Buil Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82661486",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f256bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:26:17 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:======================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:26:40 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:26:40 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 75:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(63765,[0,1,2,4,5...|[-322.26715326891...|[0.99999915565628...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-520.00195122323...|[1.0,3.6284485193...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-161.36232498969...|[1.0,1.4887069201...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-161.36232498969...|[1.0,1.4887069201...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-161.36232498969...|[1.0,1.4887069201...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-161.36232498969...|[1.0,1.4887069201...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-161.36232498969...|[1.0,1.4887069201...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-161.36232498969...|[1.0,1.4887069201...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-161.36232498969...|[1.0,1.4887069201...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-127.21534387965...|[1.0,1.3525334383...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,7...|[-156.67488280776...|[1.0,3.6383881016...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,1...|[-520.07564033763...|[4.04542964561942...|       1.0|\n",
      "|  0.0|(63765,[0,1,2,4,1...|[-235.29455145573...|[1.0,4.3100022575...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,1...|[-73.166181570647...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,1...|[-660.37991431509...|[1.0,2.9191182609...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,4,1...|[-727.75381695039...|[2.56069238312772...|       1.0|\n",
      "|  0.0|(63765,[0,1,2,4,1...|[-736.71046657889...|[0.99999999999971...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,5,7...|[-676.62304683989...|[0.99944433572656...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,5,7...|[-1400.8552374069...|[1.0,2.3946738535...|       0.0|\n",
      "|  0.0|(63765,[0,1,2,5,7...|[-667.85319396466...|[0.99999999999986...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "0:00:00.000042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes()\n",
    "prediction = nb.fit(train)\n",
    "test_results = prediction.transform(test)\n",
    "start_time = datetime.now()\n",
    "train_time = datetime.now() - start_time  \n",
    "test_results.show()\n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9dc9e443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:26:50 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:======================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:27:12 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       1.0|13963|\n",
      "|  0.0|       0.0|78292|\n",
      "|  1.0|       1.0|68842|\n",
      "|  1.0|       0.0|17618|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_results.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc491516",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0adb7738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:32:56 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:33:17 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 104:=====================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:33:40 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:33:40 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 108:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78292. 13963.]\n",
      " [17618. 68842.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#important: need to cast to float type, and order by prediction, else it won't work\n",
    "preds_and_labels = test_results.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "\n",
    "#select only prediction and label columns\n",
    "preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1625e028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:33:54 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:=====================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.8230968396441363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "acc_eva = MulticlassClassificationEvaluator()\n",
    "acc = acc_eva.evaluate(test_results)\n",
    "print('Accuracy of model: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d2b16a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c030040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:34:22 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 112:=====================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:34:43 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:34:44 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 114:>                                                      (0 + 16) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:34:45 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/03/28 02:34:45 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:=====================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:05 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "23/03/28 02:35:06 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/03/28 02:35:06 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:06 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 116:===========================>                          (16 + 16) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:07 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:07 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 118:===========================>                          (16 + 16) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:09 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:09 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 120:=================================================>     (29 + 3) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:10 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:11 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 122:>                                                      (0 + 16) / 32]\r",
      "\r",
      "[Stage 122:===========================>                          (16 + 16) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:13 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:13 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:=====================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:14 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:15 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 126:=========================================>             (24 + 8) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:17 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:18 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:==============================>                       (18 + 14) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:19 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:20 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 130:============================>                         (17 + 15) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:21 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:22 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 132:===========================>                          (16 + 16) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:23 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:23 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 134:>                                                      (0 + 16) / 32]\r",
      "\r",
      "[Stage 134:===========================>                          (16 + 16) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:24 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.000106\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(maxIter=10, regParam=0.3)\n",
    "pre_lg = lg.fit(train)\n",
    "result_lg = pre_lg.transform(test)\n",
    "start_time = datetime.now()\n",
    "train_time = datetime.now() - start_time \n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "886acbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:31 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 136:=====================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:35:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       1.0|13699|\n",
      "|  0.0|       0.0|78556|\n",
      "|  1.0|       1.0|73996|\n",
      "|  1.0|       0.0|12464|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_lg.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2535f",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce68042b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:37:03 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:37:25 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 144:=====================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:37:46 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:37:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 148:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78556. 13699.]\n",
      " [12464. 73996.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#important: need to cast to float type, and order by prediction, else it won't work\n",
    "preds_and_labels_lg = result_lg.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "\n",
    "#select only prediction and label columns\n",
    "preds_and_labels_lg = preds_and_labels_lg.select(['prediction','label'])\n",
    "\n",
    "metrics_lg = MulticlassMetrics(preds_and_labels_lg.rdd.map(tuple))\n",
    "print(metrics_lg.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7185057f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/28 02:37:53 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 150:===================================================>   (30 + 2) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.8536307313470617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 150:=====================================================> (31 + 1) / 32]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "acc_eva_lg = MulticlassClassificationEvaluator()\n",
    "acc_lg = acc_eva_lg.evaluate(result_lg)\n",
    "print('Accuracy of model: {}'.format(acc_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1230a2",
   "metadata": {},
   "source": [
    "#### Nhận xét:\n",
    "- đối với việc sử dụng Pyspark, thời gian xử lý nhanh hơn, NB nhanh hơn về tốc độ xử lý so với logistic Regression\n",
    "- Tuy nhiên kết quả thì logistic lại tốt hơn về độ chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69384e11",
   "metadata": {},
   "source": [
    "##### Như vậy Pyspark cho kết quả tốt hơn cả về thời gian xử lý lân độ chính xác"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
