{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252a7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7192e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import lit\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6235287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:04:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Rating').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5dde6",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ace938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(\"shopee_final.csv\",header=True\n",
    "                      ,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a712bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.withColumn('class',lit('fake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0956ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:04:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , processed_text, class\n",
      " Schema: _c0, processed_text, class\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/tony.ng/Documents/DS-ML/final_project/project1/shopee_final.csv\n",
      "+---+--------------------+-------+\n",
      "|_c0|      processed_text|  class|\n",
      "+---+--------------------+-------+\n",
      "|  0|miếng dán hơi dầy...|neutral|\n",
      "|  1|miếng dán tồi bóc...|neutral|\n",
      "+---+--------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75e2623f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616517"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fcaf03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- processed_text: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17376be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|   class| count|\n",
      "+--------+------+\n",
      "| neutral|112092|\n",
      "|not like|186399|\n",
      "|    like|318026|\n",
      "+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:=====>                                                   (1 + 10) / 11]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.groupby('class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ebad0",
   "metadata": {},
   "source": [
    "### Precprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e53746f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn('length', length(df1['processed_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab983c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:04:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , processed_text, class\n",
      " Schema: _c0, processed_text, class\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/tony.ng/Documents/DS-ML/final_project/project1/shopee_final.csv\n",
      "+---+--------------------+--------+------+\n",
      "|_c0|      processed_text|   class|length|\n",
      "+---+--------------------+--------+------+\n",
      "|  0|miếng dán hơi dầy...| neutral|    28|\n",
      "|  1|miếng dán tồi bóc...| neutral|    53|\n",
      "|  2|cường_lực trắng m...|not like|    23|\n",
      "|  3|hàng cảm_quan đầu...|not like|    63|\n",
      "|  4|chất_lượng cường_...|not like|    92|\n",
      "+---+--------------------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594b92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:04:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , processed_text, class\n",
      " Schema: _c0, processed_text, class\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/tony.ng/Documents/DS-ML/final_project/project1/shopee_final.csv\n",
      "+--------+------------------+----------------+\n",
      "|   class|          avg(_c0)|     avg(length)|\n",
      "+--------+------------------+----------------+\n",
      "| neutral|300455.96634014917|37.0210264839508|\n",
      "|not like| 295933.3021260844|  41.23207932699|\n",
      "|    like| 318231.5773678882|40.7444218407763|\n",
      "+--------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('class').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68208f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1.select('processed_text','class','length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7d0c9b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|      processed_text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|miếng dán hơi dầy...| neutral|    28|\n",
      "|miếng dán tồi bóc...| neutral|    53|\n",
      "|cường_lực trắng m...|not like|    23|\n",
      "|hàng cảm_quan đầu...|not like|    63|\n",
      "|chất_lượng cường_...|not like|    92|\n",
      "|kính chất_lượng k...|not like|    33|\n",
      "|kính cường_lực dở...|not like|   118|\n",
      "|vỡ bắt_làm hoàn t...|not like|    29|\n",
      "|kính bụi dính kín...|not like|    33|\n",
      "|đóng hàng cường_l...| neutral|    22|\n",
      "|hàng cường_lực xi...|not like|    61|\n",
      "|không_vừa chất_lư...|not like|    24|\n",
      "|                  bé|not like|     2|\n",
      "|         đo thử chán|not like|    11|\n",
      "|   hàng miếng bảo_vệ|not like|    17|\n",
      "|sản_phẩm miết chặ...|not like|    76|\n",
      "|chính_xác sản_phẩ...|not like|   138|\n",
      "|     hàng hãng lưu_ý|not like|    15|\n",
      "|chất_lượng sản_ph...|not like|   112|\n",
      "|cường_lực mô_tả b...|not like|    77|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6eefe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data = data.filter(data['processed_text'].isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c2e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20896"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9121783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(data['processed_text'].isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d85e9b",
   "metadata": {},
   "source": [
    "### Feature & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "380fb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BsTextExtractor(Transformer, HasInputCol, HasOutputCol):\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(BsTextExtractor, self).__init__() \n",
    "        kwargs = self._input_kwargs \n",
    "        self.setParams(**kwargs)\n",
    "        \n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None): \n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    def _transform(self, dataset):\n",
    "        def f(s):\n",
    "            cleaned_text = BeautifulSoup(s).text \n",
    "            return cleaned_text\n",
    "        t = StringType()\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udf(f, t)(in_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c29777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extractor = BsTextExtractor(inputCol=\"processed_text\", outputCol=\"cleaned_text\")\n",
    "tokenizer = Tokenizer(inputCol='cleaned_text', outputCol='token_text')\n",
    "stopremove= StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens', outputCol='c_vec')\n",
    "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\n",
    "ham_spam_to_num = StringIndexer(inputCol='class',outputCol='label', handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "680a2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols =['tf_idf','length'],\n",
    "                           outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c521930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages=[ham_spam_to_num,\n",
    "                                  text_extractor,\n",
    "                                  tokenizer,\n",
    "                                  stopremove,\n",
    "                                  count_vec,\n",
    "                                  idf,\n",
    "                                  clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1793128a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cleaner = data_prep_pipe.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eac4664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaner.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd0c6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.select('label','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f18affa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:05:21 WARN DAGScheduler: Broadcasting large task binary with size 1628.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 26:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  2.0|(55015,[13,75,182...|\n",
      "|  2.0|(55015,[75,125,18...|\n",
      "|  1.0|(55015,[11,38,54,...|\n",
      "|  1.0|(55015,[1,2,23,50...|\n",
      "|  1.0|(55015,[2,20,44,4...|\n",
      "|  1.0|(55015,[2,23,216,...|\n",
      "|  1.0|(55015,[10,21,32,...|\n",
      "|  1.0|(55015,[5,139,197...|\n",
      "|  1.0|(55015,[75,112,21...|\n",
      "|  2.0|(55015,[1,24,37,2...|\n",
      "|  1.0|(55015,[0,1,93,19...|\n",
      "|  1.0|(55015,[2,23,150,...|\n",
      "|  1.0|(55015,[37,55014]...|\n",
      "|  1.0|(55015,[57,100,45...|\n",
      "|  1.0|(55015,[1,182,789...|\n",
      "|  1.0|(55015,[0,14,108,...|\n",
      "|  1.0|(55015,[0,1,13,40...|\n",
      "|  1.0|(55015,[1,215,332...|\n",
      "|  1.0|(55015,[0,1,2,8,2...|\n",
      "|  1.0|(55015,[5,16,40,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clean_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91be6233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|  0.0|307718|\n",
      "|  1.0|179611|\n",
      "|  2.0|108292|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "232c8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = clean_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d6c877",
   "metadata": {},
   "source": [
    "## Buil Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82661486",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f256bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c16b63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:05:23 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:05:43 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prediction = nb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7025d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = prediction.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "478cbc5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:05:44 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 33:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-163.22332905690...|[1.0,8.0507389199...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-130.15032816998...|[1.0,7.2096319786...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-130.15032816998...|[1.0,7.2096319786...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-130.15032816998...|[1.0,7.2096319786...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-130.15032816998...|[1.0,7.2096319786...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-130.15032816998...|[1.0,7.2096319786...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-130.15032816998...|[1.0,7.2096319786...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-130.15032816998...|[1.0,7.2096319786...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-446.81883077448...|[1.0,3.4550345843...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-402.67865209540...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-287.93399718176...|[0.99999999997098...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-356.62826093383...|[1.0,1.7210096055...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-1593.5181024194...|[6.07528595108377...|       2.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-840.95576861016...|[2.19055865587874...|       2.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-429.01702900852...|[0.99999999999986...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,5...|[-79.242114095513...|[0.99999999932635...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,6...|[-118.11465550260...|[1.0,7.7184415900...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,6...|[-118.11465550260...|[1.0,7.7184415900...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,6...|[-500.58797365015...|[0.99999981832219...|       0.0|\n",
      "|  0.0|(55015,[0,1,2,3,6...|[-386.70088840452...|[0.99999999999999...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dc9e443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:05:54 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:06:13 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  2.0|       0.0| 8534|\n",
      "|  1.0|       1.0|34394|\n",
      "|  0.0|       1.0| 4562|\n",
      "|  1.0|       0.0| 4442|\n",
      "|  2.0|       2.0|15507|\n",
      "|  2.0|       1.0| 8363|\n",
      "|  1.0|       2.0|15165|\n",
      "|  0.0|       0.0|74597|\n",
      "|  0.0|       2.0|13377|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_results.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc491516",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1625e028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:06:13 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:====================================>                    (7 + 4) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.7067126322912657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:==================================================>     (10 + 1) / 11]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "acc_eva = MulticlassClassificationEvaluator()\n",
    "acc = acc_eva.evaluate(test_results)\n",
    "print('Accuracy of model: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e9026",
   "metadata": {},
   "source": [
    "### Nha xet:\n",
    "- Kết quả phân loại chưa thật sự được tôt khi chỉ có 70% độ chính xac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d2b16a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c030040",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(maxIter=10, regParam=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26b9099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:06:32 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:=========================================>               (8 + 3) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:06:50 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:06:51 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 41:>                                                       (0 + 11) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:06:53 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/03/23 13:06:53 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:=========================================>               (8 + 3) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:10 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:10 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/03/23 13:07:10 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:10 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:11 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:11 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:11 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:12 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:12 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:12 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:13 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:13 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 51:>                                                       (0 + 11) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:14 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:15 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:15 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:16 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 55:=========================>                               (5 + 6) / 11]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:16 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:17 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:17 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:18 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 59:==========>                                              (2 + 9) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:18 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:19 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "23/03/23 13:07:19 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    }
   ],
   "source": [
    "pre_lg = lg.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "630b9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lg = pre_lg.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "886acbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:20 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:39 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  2.0|       0.0|16834|\n",
      "|  1.0|       1.0|39110|\n",
      "|  0.0|       1.0| 4519|\n",
      "|  1.0|       0.0|13067|\n",
      "|  2.0|       2.0| 4004|\n",
      "|  2.0|       1.0|11566|\n",
      "|  1.0|       2.0| 1824|\n",
      "|  0.0|       0.0|86038|\n",
      "|  0.0|       2.0| 1979|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_lg.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2535f",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7185057f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 13:07:40 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:=========================================>               (8 + 3) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.6790793257049555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "acc_eva_lg = MulticlassClassificationEvaluator()\n",
    "acc_lg = acc_eva_lg.evaluate(result_lg)\n",
    "print('Accuracy of model: {}'.format(acc_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1230a2",
   "metadata": {},
   "source": [
    "#### Nhận xét:\n",
    "- using pyspark can lift up the computing process\n",
    "- Naive Bayes Algorithm also given a better results than normal Machine Learning "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
